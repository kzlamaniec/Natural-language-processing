corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
stoplist_file <- "./stopwords_pl.txt"
stoplist <- readLines(
stoplist_file,
encoding = "utf-8"
)
corpus <- tm_map(corpus, removeWords, stoplist)
corpus <- tm_map(corpus, content_transformer(remove_char), intToUtf8(8722))
corpus <- tm_map(corpus, content_transformer(remove_char), intToUtf8(190))
corpus <- tm_map(corpus, content_transformer(trimws))
corpus <- tm_map(corpus, stripWhitespace)
# lematyzacja
polish <- dictionary("pl_PL")
lemmatize <- function(text){
parsed_text_vec <- unlist(hunspell_parse(text, dict = polish))
lemmatized_text_vec <- hunspell_stem(parsed_text_vec, dict = polish)
for (t in 1:length(lemmatized_text_vec)) {
if(length(lemmatized_text_vec[[t]]) == 0) lemmatized_text_vec[t] <- parsed_text_vec[t]
if(length(lemmatized_text_vec[[t]])  > 1) lemmatized_text_vec[t] <- lemmatized_text_vec[[t]][1]
}
lemmatized_text <- paste(lemmatized_text_vec, collapse = " ")
return(lemmatized_text)
}
corpus <- tm_map(corpus, content_transformer(lemmatize))
# eksport przetworzonego korpusu do plikĂłw
preprocessed_dir <- "./przetworzone"
dir.create(preprocessed_dir)
writeCorpus(corpus,preprocessed_dir)
### Tworzenie macierzy czÄ™stoĹ›ci ###
corpus_dir <- "./przetworzone"
corpus <- VCorpus(
DirSource(
corpus_dir,
"UTF-8",
"*.txt"
),
readerControl = list(
language = "pl_PL"
)
)
# dodatkowe funkcje transformujÄ…ce
cut_extension <- function(document){
meta(document, "id") <- gsub("\\.txt$", "", meta(document, "id"))
return(document)
}
# wstÄ™pne przetwarzanie
corpus <- tm_map(corpus, cut_extension)
# tworzenie macierzy czÄ™stoĹ›ci
tdm_tf_all <- TermDocumentMatrix(corpus)
# transponowana tdm
tdm_tf_all <- TermDocumentMatrix(corpus)
dtm_tf_all <- DocumentTermMatrix(corpus)
dtm_tfidf_all <- DocumentTermMatrix(
corpus,
control = list(
weighting = weightTfIdf
)
)
dtm_tf_bounds <- DocumentTermMatrix(
corpus,
control = list(
bounds = list(
global = c(2,16)
)
)
)
dtm_tfidf_bounds <- DocumentTermMatrix(
corpus,
control = list(
weighting = weightTfIdf,
bounds = list(
global = c(2,16)
)
)
)
tdm_tf_bounds <- TermDocumentMatrix(
corpus,
control = list(
bounds = list(
global = c(2,16)
)
)
)
dtm_tf_all_m <- as.matrix(dtm_tf_all)
dtm_tfidf_all_m <- as.matrix(dtm_tfidf_all)
dtm_tfidf_bounds_m <- as.matrix(dtm_tfidf_bounds)
tdm_tf_bounds_m <- as.matrix(tdm_tf_bounds)
### LDA ###
# zaĹ‚adowanie bibliotek
library(topicmodels)
# utworzenie katalogu na wyniki
topics_dir <- "./topics"
dir.create(topics_dir)
# Analiza Ukrytej Alokacji Dirichlet'a (Latent Dirichlet Allocation method)
words_count <- ncol(dtm_tf_all)
topics_count <- 5
lda_model <- LDA(
dtm_tf_all,
topics_count,
method = "Gibbs",
control = list(
burnin = 2000,
thin = 100,
iter = 3000
)
)
results <- posterior(lda_model)
cols = c("lightsteelblue", "orchid", "royalblue", "grey0", "darkolivegreen4", "darkgoldenrod1")
# prezentacja tematĂłw
for (topic_no in 1:topics_count) {
topic_file <- paste(
topics_dir,
paste("Temat", topic_no, ".png"),
sep = "/"
)
png(topic_file)
par(mai = c(1,2,1,1))
topic <- tail(sort(results$terms[topic_no,]),20)
barplot(
topic,
horiz = TRUE,
las = 1,
main = paste("Temat", topic_no),
xlab = "PrawdopodobieĹ„stwo",
col = cols[topic_no]
)
dev.off()
}
#prezentacja dokumentĂłw
plot_file <- paste(topics_dir, "Dokumenty.png",sep = "/")
png(plot_file)
par(mai = c(1,4,1,1))
barplot(
t(results$topics),
horiz = TRUE,
las = 1,
main = "Dokumenty",
xlab = "PrawdopodobieĹ„stwo",
col = cols
)
dev.off()
### keywords ###
# zaĹ‚adowanie bibliotek
library(wordcloud)
# zaĹ‚adowanie skryptu z macierzÄ… czÄ™stoĹ›ci
#source_file <- "./scripts/frequency_matrix.R"
#source(source_file)
# utworzenie katalogu na wyniki
clouds_dir <- "./clouds"
dir.create(clouds_dir)
# waga tf jako miara waĹĽnoĹ›ci sĹ‚Ăłw w dokumentach
for (doc_no in 1:length(corpus)) {
print(rownames(dtm_tf_all_m)[doc_no])
print(head(sort(dtm_tf_all_m[doc_no,], decreasing = T)))
}
# waga tfidf jako miara waĹĽnoĹ›ci sĹ‚Ăłw w dokumentach
for (doc_no in 1:length(corpus)) {
print(rownames(dtm_tfidf_all_m)[doc_no])
print(head(sort(dtm_tfidf_all_m[doc_no,], decreasing = T)))
}
# prawdopodobieĹ„stwo w lda jako miara waĹĽnosci sĹ‚Ăłw
#chmury tagĂłw
for (doc_no in 1:length(corpus)) {
cloud_file <- paste(
clouds_dir,
paste(corpus[[doc_no]]$meta$id, ".png", sep = ""),
sep = "/"
)
png(cloud_file)
wordcloud(
corpus[doc_no],
max.words = 200,
colors = brewer.pal(8,"Blues")
)
dev.off()
}
## Reduction
library(lsa)
# zaĹ‚adowanie skryptu z macierzÄ… czÄ™stoĹ›ci
source_file <- "./scripts/frequency_matrix.R"
source(source_file)
# utworzenie katalogu na wyniki
reduction_dir <- "./reduction"
dir.create(reduction_dir)
# legenda
doc_names <- rownames(dtm_tfidf_bounds)
doc_count <- length(doc_names)
legend <- paste(
paste(
"d",
1:doc_count,
sep = ""
),
doc_names,
sep = " -> "
)
options(scipen = 5)
# kolory
clusters_pattern <- c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5)
cols = c("purple", "turquoise", "orange", "lightskyblue", "darkseagreen", "hotpink")
cols_pattern <- cols[clusters_pattern]
names(clusters_pattern) <- doc_names
names(cols_pattern) <- doc_names
# analiza gĹ‚Ăłwnych skĹ‚adowych
pca_model <- prcomp(dtm_tfidf_bounds)
x <- pca_model$x[,1]
y <- pca_model$x[,2]
plot_file <- paste(
reduction_dir,
"pca.png",
sep = "/"
)
png(plot_file, width = 800)
par(mar = c(4, 4, 4, 25), xpd = TRUE)
plot(
x,
y,
main = "Analiza gĹ‚Ăłwnych skĹ‚adowych",
xlab = "PC1",
ylab = "PC2",
col = cols_pattern,
pch = 16
)
text(
x,
y,
paste(
"d",
1:doc_count,
sep = ""
),
col = cols_pattern,
pos = 1
)
legend(
"topright",
inset = c(-0.9, 0.1),
legend,
text.col = cols_pattern
)
dev.off()
# analiza ukrytych wymiarĂłw semantycznych
# dekompozycja wedĹ‚ug wartoĹ›ci osobliwych
lsa_model <- lsa(tdm_tf_bounds_m)
coord_docs <- lsa_model$dk%*%diag(lsa_model$sk)
coord_terms <- lsa_model$tk%*%diag(lsa_model$sk)
terms_importance <- diag(
lsa_model$tk%*%diag(lsa_model$sk)%*%t(diag(lsa_model$sk))%*%t(lsa_model$tk)
)
important_terms <- names(
tail(
sort(terms_importance),
30
)
)
own_terms <- c("arlen", "eragon", "bilbo", "yennefer", "ciri", "jaskier", "geralt", "frodo", "gandalf", "halt", "ork", "horace")
current_terms <- own_terms
x1 <- coord_docs[,1]
y1 <- coord_docs[,2]
x2 <- coord_terms[current_terms,1]
y2 <- coord_terms[current_terms,2]
plot_file <- paste(
reduction_dir,
"lsa.png",
sep = "/"
)
png(plot_file, width = 800)
par(mar = c(4, 4, 4, 25), xpd = TRUE)
plot(
x1,
y1,
main = "Analiza ukrytych wymiarĂłw semantycznych",
xlab = "SD1",
ylab = "SD2",
col = cols_pattern,
pch = 16
)
text(
x1,
y1,
paste(
"d",
1:doc_count,
sep = ""
),
col = cols_pattern,
pos = 1
)
points(
x2,
y2,
pch = 15,
col = "magenta"
)
text(
x2,
y2,
rownames(coord_terms[current_terms,]),
col = "magenta",
pos = 2
)
legend(
"topright",
inset = c(-0.9, 0.1),
legend,
text.col = cols_pattern
)
dev.off()
# Analiza skupieĹ„
# zaĹ‚adowanie bibliotek
library(proxy)
library(dendextend)
library(corrplot)
library(flexclust)
# zaĹ‚adowanie skryptu z macierzÄ… czÄ™stoĹ›ci
source_file <- "./scripts/frequency_matrix.R"
source(source_file)
# utworzenie katalogu na wyniki
clusters_dir <- "./clusters"
dir.create(clusters_dir)
# analiza skupieĹ„
clusters_pattern <- c(1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3)
cols = c("purple", "turquoise", "orange", "lightskyblue", "darkseagreen", "hotpink")
cols_pattern <- cols[clusters_pattern]
frequency_matrix <- dtm_tfidf_bounds_m
measure <- "cosine"
method <- "ward.D2"
name <- "tfidf_bounds"
doc_names <- rownames(frequency_matrix)
doc_count <- length(doc_names)
names(clusters_pattern) <- doc_names
names(cols_pattern) <- doc_names
dist_matrix <- dist(frequency_matrix, method = measure)
hierarch_clust <- hclust(dist_matrix, method = method)
plot_file <- paste(
clusters_dir,
paste("dend_",name,"_base.png", sep = ""),
sep = "/"
)
png(plot_file)
plot(hierarch_clust)
dev.off()
dend <- as.dendrogram(hierarch_clust)
clusters_count <- find_k(dend)$k
plot_file <- paste(
clusters_dir,
paste("dend_",name,"_color.png", sep = ""),
sep = "/"
)
dend_colored <- color_branches(
dend,
k = clusters_count,
col = cols
)
png(plot_file, width = 600)
par(mai = c(1,1,1,4))
plot(dend_colored, horiz = T)
dev.off()
plot_file <- paste(
clusters_dir,
paste("dend_",name,"_pattern.png", sep = ""),
sep = "/"
)
dend_colored <- color_branches(
dend,
col = cols_pattern[dend %>% labels]
)
png(plot_file, width = 600)
par(mai = c(1,1,1,4))
plot(dend_colored, horiz = T)
dev.off()
clusters <- cutree(hierarch_clust, k = clusters_count)
clusters_matrix = matrix(0, doc_count, clusters_count)
rownames(clusters_matrix) <- doc_names
for (doc in 1:doc_count) {
clusters_matrix[doc, clusters[doc]] <- 1
}
plot_file <- paste(
clusters_dir,
paste("matrix_",name,".png", sep = ""),
sep = "/"
)
png(plot_file)
# par(mai = c(1,1,1,4))
corrplot(clusters_matrix)
dev.off()
rand_pattern_experiment <- comPart(clusters, clusters_pattern)
rand_experiment1_experiment2 <- comPart(clusters_1, clusters_2)
plot_file <- paste(
clusters_dir,
"FM_index.png",
sep = "/"
)
png(plot_file)
Bk_plot(
dend_1,
dend_2,
add_E = F,
rejection_line_asymptotic = F,
main = "Indeks Fawlkes'a - Mallows'a"
)
dev.off()
install.packages("dendextend")
library(proxy)
library(dendextend)
library(corrplot)
library(flexclust)
install.packages("dendextend")
library(proxy)
library(dendextend)
library(corrplot)
library(flexclust)
library(dendextend)
install.packages("dendextend")
install.packages(c("ggplot2", "viridis"))
install.packages("dendextend")
library(corrplot)
library(flexclust
)
# zaĹ‚adowanie bibliotek
library(proxy)
library(dendextend)
library(corrplot)
library(flexclust)
# zaĹ‚adowanie skryptu z macierzÄ… czÄ™stoĹ›ci
source_file <- "./scripts/frequency_matrix.R"
source(source_file)
# utworzenie katalogu na wyniki
clusters_dir <- "./clusters"
dir.create(clusters_dir)
clusters_pattern <- c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5)
cols = c("purple", "turquoise", "orange", "lightskyblue", "darkseagreen", "hotpink")
cols_pattern <- cols[clusters_pattern]
frequency_matrix <- dtm_tfidf_bounds_m
measure <- "cosine"
method <- "ward.D2"
name <- "tfidf_bounds"
doc_names <- rownames(frequency_matrix)
doc_count <- length(doc_names)
names(clusters_pattern) <- doc_names
names(cols_pattern) <- doc_names
dist_matrix <- dist(frequency_matrix, method = measure)
hierarch_clust <- hclust(dist_matrix, method = method)
plot_file <- paste(
clusters_dir,
paste("dend_",name,"_base.png", sep = ""),
sep = "/"
)
png(plot_file)
plot(hierarch_clust)
dev.off()
dend <- as.dendrogram(hierarch_clust)
clusters_count <- find_k(dend)$k
plot_file <- paste(
clusters_dir,
paste("dend_",name,"_color.png", sep = ""),
sep = "/"
)
dend_colored <- color_branches(
dend,
k = clusters_count,
col = cols
)
png(plot_file, width = 600)
par(mai = c(1,1,1,4))
plot(dend_colored, horiz = T)
dev.off()
plot_file <- paste(
clusters_dir,
paste("dend_",name,"_pattern.png", sep = ""),
sep = "/"
)
dend_colored <- color_branches(
dend,
col = cols_pattern[dend %>% labels]
)
png(plot_file, width = 600)
par(mai = c(1,1,1,4))
plot(dend_colored, horiz = T)
dev.off()
clusters <- cutree(hierarch_clust, k = clusters_count)
clusters_matrix = matrix(0, doc_count, clusters_count)
rownames(clusters_matrix) <- doc_names
for (doc in 1:doc_count) {
clusters_matrix[doc, clusters[doc]] <- 1
}
plot_file <- paste(
clusters_dir,
paste("matrix_",name,".png", sep = ""),
sep = "/"
)
png(plot_file)
# par(mai = c(1,1,1,4))
corrplot(clusters_matrix)
dev.off()
rand_pattern_experiment <- comPart(clusters, clusters_pattern)
rand_experiment1_experiment2 <- comPart(clusters_1, clusters_2)
plot_file <- paste(
clusters_dir,
"FM_index.png",
sep = "/"
)
png(plot_file)
Bk_plot(
dend_1,
dend_2,
add_E = F,
rejection_line_asymptotic = F,
main = "Indeks Fawlkes'a - Mallows'a"
)
dev.off()
